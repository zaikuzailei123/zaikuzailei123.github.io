<!DOCTYPE html><html><head>
      <title>2021-5-14-Pytorch &#x4EE3;&#x7801;&#x6C47;&#x603B;</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="1-%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE">1 &#x57FA;&#x7840;&#x914D;&#x7F6E;</h1>

<h2 class="mume-header" id="%E6%A3%80%E6%9F%A5pytorch%E7%89%88%E6%9C%AC">&#x68C0;&#x67E5;PyTorch&#x7248;&#x672C;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>__version__
torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda              <span class="token comment"># Corresponding CUDA version</span>
torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>version<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Corresponding cuDNN version</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>get_device_name<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>   <span class="token comment"># GPU type</span>
</pre><h2 class="mume-header" id="%E5%9B%BA%E5%AE%9A%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90">&#x56FA;&#x5B9A;&#x968F;&#x673A;&#x79CD;&#x5B50;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E6%8C%87%E5%AE%9A%E7%A8%8B%E5%BA%8F%E5%9C%A8%E7%89%B9%E5%AE%9A%E7%9A%84gpu%E4%B8%8A%E8%BF%90%E8%A1%8C">&#x6307;&#x5B9A;&#x7A0B;&#x5E8F;&#x5728;&#x7279;&#x5B9A;&#x7684;GPU&#x4E0A;&#x8FD0;&#x884C;</h2>

<p>&#x5728;&#x547D;&#x4EE4;&#x884C;&#x4E2D;&#x8BBE;&#x7F6E;&#x73AF;&#x5883;&#x53D8;&#x91CF;CUDA_VISIBLE_DEVICES=0,1<br>
&#x5728;&#x4EE3;&#x7801;&#x4E2D;&#x8BBE;&#x7F6E;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">&apos;CUDA_VISIBLE_DEVICES&apos;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&apos;0,1&apos;</span>
</pre><h2 class="mume-header" id="%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%9C%89cuda%E6%94%AF%E6%8C%81">&#x5224;&#x65AD;&#x662F;&#x5426;&#x6709;cuda&#x652F;&#x6301;</h2>

<pre data-role="codeBlock" data-info class="language-"><code>torch.cuda.is_available()
</code></pre><h2 class="mume-header" id="cudnn-benchmark-%E6%A8%A1%E5%BC%8F">cuDNN benchmark &#x6A21;&#x5F0F;</h2>

<p>&#x8BBE;&#x7F6E; torch.backends.cudnn.benchmark=True &#x5C06;&#x4F1A;&#x8BA9;&#x7A0B;&#x5E8F;&#x5728;&#x5F00;&#x59CB;&#x65F6;&#x82B1;&#x8D39;&#x4E00;&#x70B9;&#x989D;&#x5916;&#x65F6;&#x95F4;&#xFF0C;&#x4E3A;&#x6574;&#x4E2A;&#x7F51;&#x7EDC;&#x7684;&#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;(&#x6216;&#x8005;&#x5176;&#x4ED6;&#x5C42;)&#x641C;&#x7D22;&#x6700;&#x9002;&#x5408;&#x5B83;&#x7684;&#x5377;&#x79EF;&#x5B9E;&#x73B0;&#x7B97;&#x6CD5;&#xFF0C;&#x8FDB;&#x800C;&#x5B9E;&#x73B0;&#x7F51;&#x7EDC;&#x7684;&#x52A0;&#x901F;&#x3002;&#x9002;&#x7528;&#x573A;&#x666F;&#x662F;&#x8BAD;&#x7EC3;&#x9636;&#x6BB5;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x56FA;&#x5B9A;&#xFF08;&#x4E0D;&#x662F;&#x52A8;&#x6001;&#x53D8;&#x5316;&#x7684;&#xFF09;&#xFF0C;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x5165;&#x5F62;&#x72B6;&#xFF08;&#x5305;&#x62EC; <strong>batch size</strong>&#xFF0C;&#x56FE;&#x7247;&#x5927;&#x5C0F;&#xFF0C;&#x8F93;&#x5165;&#x7684;&#x901A;&#x9053;&#xFF09;&#x662F;&#x4E0D;&#x53D8;&#x7684;&#x3002;&#x53CD;&#x4E4B;&#xFF0C;&#x5982;&#x679C;&#x5377;&#x79EF;&#x5C42;&#x7684;&#x8BBE;&#x7F6E;&#x4E00;&#x76F4;&#x53D8;&#x5316;&#xFF0C;&#x5C06;&#x4F1A;&#x5BFC;&#x81F4;&#x7A0B;&#x5E8F;&#x4E0D;&#x505C;&#x5730;&#x505A;&#x4F18;&#x5316;&#xFF0C;&#x53CD;&#x800C;&#x4F1A;&#x8017;&#x8D39;&#x66F4;&#x591A;&#x7684;&#x65F6;&#x95F4;&#x3002;<br>
&#x4F18;&#x5316;&#x539F;&#x56E0;&#xFF1A;&#x4E0D;&#x540C;&#x5377;&#x79EF;&#x6838;&#x548C;&#x8F93;&#x5165;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7B97;&#x6CD5;&#x8BA1;&#x7B97;&#x901F;&#x5EA6;&#x4E0D;&#x4E00;&#x6837;&#xFF0C;&#x6253;&#x5F00;&#x5F00;&#x5173;&#x540E;torch&#x4F1A;&#x6839;&#x636E;&#x56FA;&#x5B9A;&#x7684;&#x5377;&#x79EF;&#x6838;&#x548C;&#x8F93;&#x5165;&#x4E3A;&#x6BCF;&#x4E00;&#x5C42;&#x81EA;&#x52A8;&#x9009;&#x62E9;&#x901F;&#x5EA6;&#x6700;&#x5FEB;&#x7684;&#x7B97;&#x6CD5;&#x548C;&#x4F18;&#x5316;&#x65B9;&#x6CD5;&#x3002;<br>
&#x5728;&#x6700;&#x5F00;&#x59CB;&#x5904;&#x8BBE;&#x7F6E;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token comment"># &#x9ED8;&#x8BA4;False</span>
</pre><h2 class="mume-header" id="%E6%B8%85%E9%99%A4gpu%E5%AD%98%E5%82%A8">&#x6E05;&#x9664;GPU&#x5B58;&#x50A8;</h2>

<p>&#x573A;&#x666F;&#xFF1A;&#x6709;&#x65F6;Ctrl-C&#x540E;&#x7A0B;&#x5E8F;&#x6CA1;&#x6709;&#x7ACB;&#x5373;&#x91CA;&#x653E;&#xFF0C;&#x9700;&#x8981;&#x624B;&#x52A8;&#x6E05;&#x7A7A;&#x3002;&#x5728;Pytorch&#x5185;&#x90E8;&#x53EF;&#x4EE5;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><p>&#x6216;&#x8005;&#x5728;&#x547D;&#x4EE4;&#x884C;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="shell" class="language-shell"><span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> PID
<span class="token function">kill</span> -9 <span class="token punctuation">[</span>pid<span class="token punctuation">]</span>
</pre><p>&#x6216;&#x8005;&#x76F4;&#x63A5;&#x91CD;&#x7F6E;&#x6CA1;&#x6709;&#x88AB;&#x6E05;&#x7A7A;&#x7684;GPU</p>
<pre data-role="codeBlock" data-info="shell" class="language-shell">nvidia-smi --gpu-reset -i <span class="token punctuation">[</span>gpu_id<span class="token punctuation">]</span>
</pre><h1 class="mume-header" id="2-%E5%BC%A0%E9%87%8F%E5%A4%84%E7%90%86">2. &#x5F20;&#x91CF;&#x5904;&#x7406;</h1>

<h2 class="mume-header" id="%E5%BC%A0%E9%87%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF">&#x5F20;&#x91CF;&#x7684;&#x57FA;&#x672C;&#x4FE1;&#x606F;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">tensor<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># Data type</span>
tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># Shape of the tensor</span>
tensor<span class="token punctuation">.</span>shape        <span class="token comment"># Shape of the tensor</span>
tensor<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># Number of dimensions</span>
</pre><h2 class="mume-header" id="%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2">&#x6570;&#x636E;&#x7C7B;&#x578B;&#x8F6C;&#x6362;</h2>

<p>Set default tensor type. Float &#x7C7B;&#x578B;&#x6BD4;Double&#x7C7B;&#x578B;&#x5FEB;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span>

<span class="token comment"># &#x7C7B;&#x578B;&#x8F6C;&#x6362;</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># &#x4E0E;np.array&#x8F6C;&#x6362;</span>
ndarray <span class="token operator">=</span> tensor<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>ndarray<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># &#x4E0E;PIL.Image&#x8F6C;&#x6362;</span>
<span class="token comment"># Pytorch&#x4E2D;&#x5F20;&#x91CF;&#x9ED8;&#x8BA4;&#x91C7;&#x7528;N x C x H x W&#x7684;&#x987A;&#x5E8F;&#xFF0C;&#x5E76;&#x4E14;&#x6570;&#x636E;&#x8303;&#x56F4;&#x5728;[0,1]&#xFF0C;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x8F6C;&#x7F6E;&#x548C;&#x89C4;&#x8303;&#x5316;</span>
<span class="token comment"># torch.clamp, Clamp&#xFF08;&#x622A;&#x65AD;&#xFF09; all elements in input into the range [min,max]. Let min_value and max_value be min and max, respectively</span>
<span class="token comment"># tensor.permute(): &#x7EF4;&#x5EA6;&#x4EA4;&#x6362;</span>
image <span class="token operator">=</span> PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>tensor <span class="token operator">*</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">.</span>byte<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>to_pil_image<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>

tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>
tensor <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token operator">/</span>functional<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E4%BB%8E%E5%8F%AA%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E5%80%BC%E7%9A%84%E5%BC%A0%E9%87%8F%E6%8F%90%E5%8F%96%E5%87%BA%E6%95%B0%E5%80%BC">&#x4ECE;&#x53EA;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x503C;&#x7684;&#x5F20;&#x91CF;&#x63D0;&#x53D6;&#x51FA;&#x6570;&#x503C;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">value <span class="token operator">=</span> tensor<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E6%89%93%E4%B9%B1%E9%A1%BA%E5%BA%8F">&#x6253;&#x4E71;&#x987A;&#x5E8F;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">tensor <span class="token operator">=</span> tensor<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span>tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>         <span class="token comment"># Shuffle the first dimension</span>
</pre><h2 class="mume-header" id="%E5%A4%8D%E5%88%B6%E5%BC%A0%E9%87%8F">&#x590D;&#x5236;&#x5F20;&#x91CF;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># Operation                     | New/Shared Memory | Still in computation graph |</span>
tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment">#  |      New          |           Yes              |</span>
tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token comment">#  |      Shared       |           No               |</span>
tensor<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment">#  |      New          |           No               |     </span>
</pre><h2 class="mume-header" id="%E5%BC%A0%E9%87%8F%E6%8B%BC%E6%8E%A5">&#x5F20;&#x91CF;&#x62FC;&#x63A5;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># tensor.cat&#x6CBF;&#x7740;&#x7ED9;&#x5B9A;&#x7684;&#x7EF4;&#x5EA6;&#x62FC;&#x63A5;&#xFF0C;torch.stack&#x4F1A;&#x65B0;&#x589E;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#xFF0C;&#x4F8B;&#x5982;3&#x4E2A;10 x 5 &#x7684;&#x5F20;&#x91CF;&#xFF0C;torch.cat&#x7ED3;&#x679C;&#x662F;30 x 5&#xFF0C;&#x800C;torch.stack&#x662F;3 x 10 x 5</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>list_of_tensors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>list_of_tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E5%B0%86%E6%95%B4%E6%95%B0%E8%BD%AC%E6%8D%A2%E4%B8%BAone-hot">&#x5C06;&#x6574;&#x6570;&#x8F6C;&#x6362;&#x4E3A;one-hot</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># tensorflow(keras) &#x65B9;&#x6CD5;&#xFF1A;</span>
tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>ndarray<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

<span class="token comment"># Pytorch&#x65B9;&#x6CD5;</span>
<span class="token comment"># torch.scatter_&#xFF1A;&#x6839;&#x636E;index&#x5BF9;src&#x7684;&#x6570;&#x636E;&#x91CD;&#x65B0;&#x5206;&#x914D;&#x5230;one_hot&#x6570;&#x7EC4;&#x4E2D;</span>
N <span class="token operator">=</span> tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
one_hot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
one_hot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> src<span class="token operator">=</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E5%BE%97%E5%88%B0%E9%9D%9E%E9%9B%B6%E9%9B%B6%E5%85%83%E7%B4%A0">&#x5F97;&#x5230;&#x975E;&#x96F6;/&#x96F6;&#x5143;&#x7D20;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>           <span class="token comment"># Index of non-zero elements</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>      <span class="token comment"># Index of zeros elements</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># number of non-zero element</span>
torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>tensor<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Number of zero element</span>
</pre><h2 class="mume-header" id="%E5%88%A4%E6%96%AD%E4%B8%A4%E4%B8%AA%E5%BC%A0%E9%87%8F%E6%98%AF%E5%90%A6%E7%9B%B8%E7%AD%89">&#x5224;&#x65AD;&#x4E24;&#x4E2A;&#x5F20;&#x91CF;&#x662F;&#x5426;&#x76F8;&#x7B49;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>        <span class="token comment"># float tensor</span>
torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span>tensor2<span class="token punctuation">)</span>            <span class="token comment"># int tensor</span>
</pre><h2 class="mume-header" id="%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95">&#x77E9;&#x9635;&#x4E58;&#x6CD5;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># Matrix multiplication: (m*n)*(n*p) -&gt; (m*p)</span>
result <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>

<span class="token comment"># Batch matrix multiplication: (b*m*n)*(b*n*p) -&gt; (b*m*p)</span>
result <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span>

<span class="token comment"># Element-wise multiplication</span>
result <span class="token operator">=</span> tensor1 <span class="token operator">*</span> tensor2
</pre><h2 class="mume-header" id="%E8%AE%A1%E7%AE%97%E4%B8%A4%E7%BB%84%E6%95%B0%E6%8D%AE%E4%B8%A4%E4%B8%A4%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB">&#x8BA1;&#x7B97;&#x4E24;&#x7EC4;&#x6570;&#x636E;&#x4E24;&#x4E24;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># &#x4E0B;&#x9762;&#x7684;None&#x5347;&#x4E86;&#x7EF4;&#x5EA6;&#xFF0C;&#x518D;&#x5229;&#x7528;torch&#x7684;broadcast&#x6269;&#x5C55;&#x6210;&#x8BB8;&#x591A;X1&#x7684;&#x539F;&#x59CB;&#x6570;&#x636E;&#x4E0E;X2&#x8FDB;&#x884C;</span>
dist <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>X1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">.</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">-</span>X2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h1 class="mume-header" id="3-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89">3. &#x6A21;&#x578B;&#x5B9A;&#x4E49;</h1>

<h2 class="mume-header" id="%E5%8D%B7%E7%A7%AF%E5%B1%82">&#x5377;&#x79EF;&#x5C42;</h2>

<p>conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)</p>
<h2 class="mume-header" id="gap%E5%B1%82global-average-pooling%E5%B1%82">GAP&#x5C42;(Global average pooling)&#x5C42;</h2>

<p>GAP&#x5C42;&#x7528;&#x4E8E;&#x66FF;&#x4EE3;CNN&#x6A21;&#x578B;&#x4E2D;&#x6700;&#x540E;&#x7684;Fully Connection Layers&#xFF0C;&#x800C;&#x662F;&#x5C06;&#x5377;&#x79EF;&#x7ED3;&#x675F;&#x540E;&#x901A;&#x8FC7;GAP&#x540E;&#x76F4;&#x63A5;&#x9001;&#x5165;&#x5230;softmax&#x5C42;&#x3002;<br>
<img src="https://paperswithcode.com/media/methods/Screen_Shot_2020-06-06_at_12.15.58_PM.png" alt></p>
<pre data-role="codeBlock" data-info="python" class="language-python">gap <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


</pre><h2 class="mume-header" id="%E5%A4%9A%E5%8D%A1%E5%90%8C%E6%AD%A5batch">&#x591A;&#x5361;&#x540C;&#x6B65;batch</h2>

<p>&#x5F53;&#x4F7F;&#x7528;torch.nn.DataParallel&#x5C06;&#x4EE3;&#x7801;&#x8FD0;&#x884C;&#x518D;&#x591A;&#x5F20;GPU&#x5361;&#x4E0A;&#x65F6;&#xFF0C;PyTorch&#x7684;BN&#x5C42;&#x9ED8;&#x8BA4;&#x64CD;&#x4F5C;&#x662F;&#x5404;&#x5361;&#x4E0A;&#x6570;&#x636E;&#x72EC;&#x7ACB;&#x5730;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;&#xFF0C;&#x540C;&#x6B65;BN&#x4F7F;&#x7528;&#x6240;&#x6709;&#x5361;&#x4E0A;&#x5730;&#x6570;&#x636E;&#x4E00;&#x8D77;&#x8BA1;&#x7B97;BN&#x5C42;&#x5730;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;&#xFF0C;<br>
&#x7F13;&#x89E3;&#x4E86;&#x5F53;&#x6279;&#x91CF;&#x5927;&#x5C0F;&#x6BD4;&#x8F83;&#x5C0F;&#x65F6;&#x5BF9;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;&#x4F30;&#x8BA1;&#x4E0D;&#x51C6;&#x5730;&#x60C5;&#x51B5;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python">sync_bn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">(</span>num_feature<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span> xxxxx<span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%B8%A4">&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x4E24;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">num_parameters <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>numel<span class="token punctuation">(</span>parameter<span class="token punctuation">)</span> <span class="token keyword">for</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><p>&#x8F93;&#x51FA;&#x6A21;&#x578B;&#x4FE1;&#x606F;&#x7684;&#x5DE5;&#x5177;&#xFF1A; <a href="https://github.com/sksq96/pytorch-summary/blob/master/torchsummary/torchsummary.py">&#x5730;&#x5740;</a></p>
<h2 class="mume-header" id="%E6%A8%A1%E5%9E%8B%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96">&#x6A21;&#x578B;&#x6743;&#x91CD;&#x521D;&#x59CB;&#x5316;</h2>

<p>&#x6CE8;&#x610F;model.modules()&#x548C;model.children()&#x7684;&#x533A;&#x522B;&#xFF1A;model.modules()&#x4F1A;&#x8FED;&#x4EE3;&#x5730;&#x904D;&#x5386;&#x6A21;&#x578B;&#x7684;&#x6240;&#x6709;&#x5B50;&#x5C42;&#xFF0C;&#x800C;model.children()&#x53EA;&#x4F1A;&#x904D;&#x5386;&#x6A21;&#x578B;&#x4E0B;&#x7684;&#x4E00;&#x5C42;&#x3002;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># Common practise for initialization.  </span>
<span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&apos;fan_out&apos;</span><span class="token punctuation">,</span>
                                      nonlinearity<span class="token operator">=</span><span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> layer<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>

<span class="token comment"># Initialization with given tensor.</span>
layer<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>

</pre><h2 class="mume-header" id="%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B">&#x4FDD;&#x5B58;&#x6A21;&#x578B;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&apos;model,pth&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># &#x5C06;&#x5728;GPU&#x4FDD;&#x5B58;&#x7684;&#x6A21;&#x578B;&#x52A0;&#x8F7D;&#x5230;CPU</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&apos;model,pth&apos;</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">&apos;cpu&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E6%8F%90%E5%8F%96imagenet%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%9F%90%E5%B1%82%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81">&#x63D0;&#x53D6;ImageNet&#x9884;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#x67D0;&#x5C42;&#x7684;&#x5377;&#x79EF;&#x7279;&#x5F81;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># VGG-16 relu5-3 feature.  </span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment"># VGG-16 pool5 feature.  </span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>features
<span class="token comment"># VGG-16 fc7 feature.  </span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># ResNet GAP feature.  </span>
model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span>
    <span class="token builtin">list</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    conv_representation <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

</pre><h2 class="mume-header" id="%E6%8F%90%E5%8F%96imagenet%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%A4%9A%E5%B1%82%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81">&#x63D0;&#x53D6;ImageNet&#x9884;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#x591A;&#x5C42;&#x7684;&#x5377;&#x79EF;&#x7279;&#x5F81;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">class</span> <span class="token class-name">FeatureExtractor</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Helper class to extract several convolution features from the given
    pre-trained model.

    Attributes:
        _model, torch.nn.Module.
        _layers_to_extract, list&lt;str&gt; or set&lt;str&gt;

    Example:
        &gt;&gt;&gt; model = torchvision.models.resnet152(pretrained=True)
        &gt;&gt;&gt; model = torch.nn.Sequential(collections.OrderedDict(
                list(model.named_children())[:-1]))
        &gt;&gt;&gt; conv_representation = FeatureExtractor(
                pretrained_model=model,
                layers_to_extract={&apos;layer1&apos;, &apos;layer2&apos;, &apos;layer3&apos;, &apos;layer4&apos;})(image)
    &quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_model<span class="token punctuation">,</span> layers_to_extract<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_model <span class="token operator">=</span> pretrained_model
        self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_layers_to_extract <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>layers_to_extract<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            conv_representation <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_model<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
                <span class="token keyword">if</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>_layers_to_extract<span class="token punctuation">:</span>
                    conv_representation<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">return</span> conv_representation

</pre><h2 class="mume-header" id="%E4%BB%A5%E8%BE%83%E5%A4%A7%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%BE%AE%E8%B0%83%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E8%BE%83%E5%B0%8F%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%BE%AE%E8%B0%83%E5%8D%B7%E7%A7%AF%E5%B1%82">&#x4EE5;&#x8F83;&#x5927;&#x5B66;&#x4E60;&#x7387;&#x5FAE;&#x8C03;&#x5168;&#x8FDE;&#x63A5;&#x5C42;&#xFF0C;&#x8F83;&#x5C0F;&#x5B66;&#x4E60;&#x7387;&#x5FAE;&#x8C03;&#x5377;&#x79EF;&#x5C42;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python">model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
finetuned_parameters <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
conv_parameters <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">id</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> finetuned_parameters<span class="token punctuation">)</span>
parameters <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&apos;params&apos;</span><span class="token punctuation">:</span> conv_parameters<span class="token punctuation">,</span> <span class="token string">&apos;lr&apos;</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
              <span class="token punctuation">{</span><span class="token string">&apos;params&apos;</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>

</pre><h1 class="mume-header" id="5-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">5. &#x6A21;&#x578B;&#x8BAD;&#x7EC3;</h1>

<h2 class="mume-header" id="%E5%B8%B8%E7%94%A8%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AA%8C%E8%AF%81%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">&#x5E38;&#x7528;&#x8BAD;&#x7EC3;&#x548C;&#x9A8C;&#x8BC1;&#x6570;&#x636E;&#x9884;&#x5904;&#x7406;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># ToTensor()&#x64CD;&#x4F5C;&#x4F1A;&#x5C06;PIL.Image&#x6216;&#x8005;&#x5F62;&#x72B6;&#x4E3A;W x H x C&#xFF0C;&#x6570;&#x503C;&#x8303;&#x56F4;[0,255]&#x7684;np.ndarray&#x8F6C;&#x6362;&#x4E3A;&#x5F62;&#x72B6;&#x4E3A;C x W x H&#xFF0C;&#x6570;&#x503C;&#x8303;&#x56F4;&#x4E3A;[0.0, 1.0]&#x7684;torch.Tensor  </span>

train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span><span class="token number">0.456</span><span class="token punctuation">,</span><span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token comment"># &#x5BF9;&#x6BD4;&#x5EA6;&#x4FEE;&#x6539;  </span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

val_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.485</span><span class="token punctuation">,</span><span class="token number">0.456</span><span class="token punctuation">,</span><span class="token number">0.406</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

</pre><h2 class="mume-header" id="%E5%9F%BA%E6%9C%AC%E7%9A%84%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81">&#x57FA;&#x672C;&#x7684;&#x8BAD;&#x7EC3;&#x4EE3;&#x7801;</h2>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">for</span> t <span class="token keyword">in</span> epoch<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">&apos;Epoch %3d&apos;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        scores <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h2 class="mume-header" id="%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91label-smoothing">&#x6807;&#x7B7E;&#x5E73;&#x6ED1;(label smoothing)</h2>

<p>&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4F1A;&#x4FC3;&#x4F7F;&#x81EA;&#x8EAB;&#x5F80;&#x6B63;&#x786E;&#x6807;&#x7B7E;&#x548C;&#x9519;&#x8BEF;&#x6807;&#x7B7E;&#x5DEE;&#x503C;&#x6700;&#x5927;&#x7684;&#x65B9;&#x5411;&#x5B66;&#x4E60;&#xFF0C;&#x5728;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x8F83;&#x5C11;&#xFF0C;&#x4E0D;&#x8DB3;&#x4EE5;&#x8868;&#x5F81;&#x6240;&#x6709;&#x7684;&#x6837;&#x672C;&#x7279;&#x5F81;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x4F1A;&#x5BFC;&#x81F4;&#x7F51;&#x7EDC;&#x8FC7;&#x62DF;&#x5408;&#x3002;&#x4E5F;&#x5C31;&#x662F;<br>
<img src="https://pic1.zhimg.com/80/v2-3a09badcdcf855242b6511e291a1d078_1440w.jpg" alt><br>
label smoothing&#x53EF;&#x4EE5;&#x89E3;&#x51B3;&#x4E0A;&#x8FF0;&#x95EE;&#x9898;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x6B63;&#x5219;&#x5316;&#x7B56;&#x7565;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x901A;&#x8FC7;soft one-hot&#x6765;&#x52A0;&#x5165;&#x566A;&#x58F0;&#xFF0C;&#x51CF;&#x5C11;&#x4E86;&#x771F;&#x5B9E;&#x6837;&#x672C;&#x6807;&#x7B7E;&#x7684;&#x7C7B;&#x522B;&#x5728;&#x8BA1;&#x7B97;&#x635F;&#x5931;&#x51FD;&#x6570;&#x65F6;&#x7684;&#x6743;&#x91CD;&#xFF0C;&#x6700;&#x7EC8;&#x8D77;&#x5230;&#x6291;&#x5236;&#x8FC7;&#x62DF;&#x5408;&#x7684;&#x6548;&#x679C;&#x3002;&#x589E;&#x52A0;label smoothing&#x540E;&#x771F;&#x5B9E;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#x6709;&#x5982;&#x4E0B;&#x6539;&#x53D8;&#xFF1A;<br>
<img src="https://pic1.zhimg.com/v2-56899017cd0d5c113edc8002997381d8_r.jpg" alt><br>
&#x4EA4;&#x53C9;&#x71B5;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7684;&#x6539;&#x53D8;&#x5982;&#x4E0B;&#xFF1A;<br>
<img src="https://pic2.zhimg.com/v2-858823f138177de7f61b725b5075e491_r.jpg" alt></p>
<p>Pytorch&#x5B9E;&#x73B0;&#x6807;&#x7B7E;&#x5E73;&#x6ED1;&#xFF1A;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">for</span> images<span class="token punctuation">,</span>labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
    images<span class="token punctuation">,</span>labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    N <span class="token operator">=</span> label<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># C is the number of classes  </span>

    smoothed_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">,</span> fill_value<span class="token operator">=</span><span class="token number">0.1</span> <span class="token operator">/</span> <span class="token punctuation">(</span>C<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    smoothed_labels<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>torch<span class="token punctuation">.</span>unsequeeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

    score <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
    log_prob <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>score<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 
    loss <span class="token operator">=</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>log_prob <span class="token operator">*</span> smoothed_labels<span class="token punctuation">)</span> <span class="token operator">/</span> N
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre>
      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>